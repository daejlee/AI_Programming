{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터 로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
    "\n",
    "train_data = pd.read_table('ratings_train.txt')\n",
    "test_data = pd.read_table('ratings_test.txt')\n",
    "\n",
    "print('Train data len: ', len(train_data))\n",
    "train_data[:5]\n",
    "\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "\n",
    "train_data.groupby('label').size()\n",
    "\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data[:5]\n",
    "\n",
    "train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']\n",
    "\n",
    "okt = Okt()\n",
    "X_train = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentences = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed = [word for word in tokenized_sentences if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(stopwords_removed)\n",
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for sentence in tqdm(test_data['document']):\n",
    "    tokenized_sentences = okt.morphs(str(sentence), stem=True) # 토큰화\n",
    "    stopwords_removed = [word for word in tokenized_sentences if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(stopwords_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x_train, y_train, x_val, y_val):\n",
    "  word_list = []\n",
    "  \n",
    "  for sentence in x_train:\n",
    "    for word in sentence:\n",
    "      word_list.append(word)\n",
    "      \n",
    "  corpus = Counter(word_list)\n",
    "  corpus_ = sorted(corpus, key=corpus.get, reverse=True)[:10000]\n",
    "  onehot_dict = {w: i+1 for i, w in enumerate(corpus_)}\n",
    "  \n",
    "  final_list_train, final_list_test = [], []\n",
    "  for sentence in x_train:\n",
    "    final_list_train.append([onehot_dict[word] for word in sentence\n",
    "                             if word in sentence in onehot_dict.keys()])\n",
    "  for sentence in x_val:\n",
    "    final_list_test.append([onehot_dict[word] for word in sentence\n",
    "                            if word in sentence in onehot_dict.keys()])\n",
    "  return np.array(final_list_train), np.array(y_train), np.array(final_list_test), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, vocab = tokenize(X_train, train_data['label'], X_test, test_data['label'])\n",
    "rev_len = [len(x) for x in x_train]\n",
    "pd.Series(rev_len).hist()\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
